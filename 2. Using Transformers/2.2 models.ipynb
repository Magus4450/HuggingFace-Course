{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoModel Class\n",
    "\n",
    "* AutoModel class and all of its relatives are simple wrappers over wide variety of models \n",
    "* Automatically generates appropriate model architecture for your checkpoint, and instantiates it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a BERT Model\n",
    "\n",
    "from transformers import BertConfig, BertModel\n",
    "\n",
    "# Building the config\n",
    "config = BertConfig()\n",
    "\n",
    "# Building the model from the config\n",
    "model = BertModel(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config contains many attributes that are used to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "BertConfig {\n",
    "  [...]\n",
    "  \"hidden_size\": 768,\n",
    "  \"intermediate_size\": 3072,\n",
    "  \"max_position_embeddings\": 512,\n",
    "  \"num_attention_heads\": 12,\n",
    "  \"num_hidden_layers\": 12,\n",
    "  [...]\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Loading Methods\n",
    "\n",
    "Creating model from default config intializes it with random values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained model\n",
    "\n",
    "from transformers import BertModel\n",
    "\n",
    "model = BertModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cache are stored by default in `~/.cache/huggingface/transformers`. Can be customized be setting HF_HOME environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "\n",
    "model.save_pretrained(\"dir\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This saves two files:\n",
    "* config.json : Stores data needed to build the model\n",
    "* pytorch_model.json : Stores state dicts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Transformer model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example sequence\n",
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer converts each of the vocab indices to input IDs as such\n",
    "\n",
    "```py\n",
    "encoded_sequences = [\n",
    "    [101, 7592, 999, 102],\n",
    "    [101, 4658, 1012, 102],\n",
    "    [101, 3835, 999, 102],\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to Tensors\n",
    "import torch\n",
    "\n",
    "model_inputs = torch.Tensor(encoded_sequences)\n",
    "\n",
    "\n",
    "# Feeding the tensor to model\n",
    "\n",
    "output = model(model_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
